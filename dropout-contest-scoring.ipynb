{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 Democratic Primary Drop Out Predictions Scoring Formulas\n",
    "\n",
    "## Author: Oliver Gladfelter\n",
    "\n",
    "### Date: Dec 9th, 2019\n",
    "### Updated: Jan 6th, 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "import statistics\n",
    "\n",
    "def kendall_tau_distance(order_a, order_b):\n",
    "    pairs = itertools.combinations(range(1, len(order_a)+1), 2)\n",
    "    distance = 0\n",
    "    for x, y in pairs:\n",
    "        a = order_a.index(x) - order_a.index(y)\n",
    "        b = order_b.index(x) - order_b.index(y)\n",
    "        if a * b < 0:\n",
    "            distance += 1\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data\n",
    "data = pd.read_csv(\"dropout-contest-6.csv\")\n",
    "data = data.drop(['Timestamp', 'Email Address', 'Do you wish to include any thoughts or explanations for your predictions?'], axis=1)\n",
    "    \n",
    "data.columns = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 'participant', 'twitter', 'privacyPreference', 'alias', 'showAnswers']\n",
    "data['privacyPreference'][45] = \"Yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some survey respondents chose one candidate twice (presumably mistakenly). This also means they left one candidate off their prediction. This function determines cases this occured and automatically fixes it by replacing one instance of the duplicated candidate with the ommitted candidate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixDoubleMissingError(index, double, missing):\n",
    "    \"\"\"\n",
    "    index = row count\n",
    "    double = name in dictionary. ex: {'Michael Bloomberg': 2}\n",
    "    missing = name in list. ex: ['Michael Bennet']\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    double = list(double) # put the name in a list\n",
    "    #double = list({'Michael Bloomberg': 2})\n",
    "    #missing = ['Michael Bennet']\n",
    "\n",
    "    secondOccurance = 0 # switch starts as off \n",
    "    for column in data.columns[:-5]: # iterate over all columns of the called row\n",
    "        if secondOccurance == 1 and data[column][index] in double:\n",
    "            data[column][index] = missing[0] # replace the second occurrence of the repeated name with the missing name\n",
    "        if data[column][index] in double:\n",
    "            secondOccurance = 1 # flip switch on\n",
    "\n",
    "for row in range(0,len(data)):\n",
    "    allCandidates  = ['Amy Klobuchar','Andrew Yang','Bernie Sanders','Cory Booker','Deval Patrick','Elizabeth Warren','Joe Biden','John Delaney','Marianne Williamson','Michael Bennet','Michael Bloomberg','Pete Buttigieg','Tom Steyer','Tulsi Gabbard']\n",
    "    candidates = []\n",
    "    for column in data.columns[:-5]:\n",
    "        candidates.append(data[column][row])\n",
    "    if (len(set(candidates))) != 14: # count number of candidates in survey response. Anything less indicates a mistake.\n",
    "        candidatesCount = {}\n",
    "        \n",
    "        # iterate over mistaken response, count how many times each candidate was selected\n",
    "        for candidate in candidates:\n",
    "            if candidate in candidatesCount:\n",
    "                candidatesCount[candidate] = candidatesCount[candidate] + 1\n",
    "            else:\n",
    "                candidatesCount[candidate] = 1\n",
    "                allCandidates.remove(candidate) # if a candidate was selected, remove from allCandidates list. By end of loop, allCandidates will actually be all MISSING candidates\n",
    "                \n",
    "        copy = dict(candidatesCount)\n",
    "\n",
    "        # remove candidates with count of 1. We only want the name of candidates selected 2+ times\n",
    "        for (key, value) in  candidatesCount.items(): \n",
    "            if value == 1:\n",
    "                del copy[key]\n",
    "\n",
    "        # call fixDoubleMissingError() function on erred row, with dictionary showing candidates with count > 1, and list of missing candidates\n",
    "        print(data['participant'][row])\n",
    "        print(copy)\n",
    "        print(allCandidates)\n",
    "        fixDoubleMissingError(row, copy, allCandidates)\n",
    "        print(\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now every row has each candidate listed once and only once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(0,len(data)):\n",
    "    for column in data.columns[:-5]:\n",
    "        candidates.append(data[column][row])\n",
    "    if (len(set(candidates))) != 14:\n",
    "        print(\"Error\") # this should never happen by this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate 'average' scores of each candidate. Who is expected to go far, according to the aggregate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidateScores = {}\n",
    "\n",
    "# find dropout num for each candidate in each guess. Add num to total value for that candidate in the dict.\n",
    "for row in range(0,len(data)):\n",
    "    for column in data.columns[:-5]:\n",
    "        if (data[column][row]) in candidateScores:\n",
    "            candidateScores[(data[column][row])] = candidateScores[(data[column][row])] + int(column)\n",
    "        else:\n",
    "            candidateScores[(data[column][row])] = int(column)\n",
    "\n",
    "# calc average by dividing each value by number of participants\n",
    "for (key, value) in  candidateScores.items(): \n",
    "    candidateScores[key] = value / len(data)\n",
    "    \n",
    "# sort dictionary by values\n",
    "candidateScoresSorted = {k: v for k, v in sorted(candidateScores.items(), key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is the predicted drop out order, according to the aggregate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Michael Bennet': 3.120879120879121,\n",
       " 'Deval Patrick': 4.0989010989010985,\n",
       " 'John Delaney': 4.252747252747253,\n",
       " 'Marianne Williamson': 4.43956043956044,\n",
       " 'Cory Booker': 5.1208791208791204,\n",
       " 'Tom Steyer': 6.241758241758242,\n",
       " 'Tulsi Gabbard': 6.252747252747253,\n",
       " 'Amy Klobuchar': 6.384615384615385,\n",
       " 'Andrew Yang': 8.23076923076923,\n",
       " 'Michael Bloomberg': 8.846153846153847,\n",
       " 'Pete Buttigieg': 10.527472527472527,\n",
       " 'Bernie Sanders': 12.142857142857142,\n",
       " 'Elizabeth Warren': 12.384615384615385,\n",
       " 'Joe Biden': 12.956043956043956}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidateScoresSorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Often, the aggregate of many predictions are more accurate than any one single prediction (this is essentially the theory Nate Silver built FiveThirtyEight on), so let's include the aggregate order in the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregateRow = {}\n",
    "\n",
    "num = 1\n",
    "\n",
    "for c in candidateScoresSorted.keys():\n",
    "    aggregateRow[num] = [c]\n",
    "    num = num + 1\n",
    "    \n",
    "aggregateRow = pd.DataFrame(aggregateRow)\n",
    "\n",
    "aggregateRow['participant'] = \"Wisdom of the crowd\"\n",
    "aggregateRow['twitter'] = \"\"\n",
    "aggregateRow['privacyPreference'] = \"fullName\"\n",
    "aggregateRow['alias'] = \"Wisdom of the crowd\"\n",
    "aggregateRow['showAnswers'] = 'Yes'\n",
    "aggregateRow['score'] = 0\n",
    "\n",
    "data = data.append(aggregateRow, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Function\n",
    "\n",
    "## edit the order of 'candidates' list in below cell before running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Michael Bennet': 1,\n",
       " 'Deval Patrick': 2,\n",
       " 'John Delaney': 3,\n",
       " 'Marianne Williamson': 4,\n",
       " 'Cory Booker': 5,\n",
       " 'Tom Steyer': 6,\n",
       " 'Tulsi Gabbard': 7,\n",
       " 'Amy Klobuchar': 8,\n",
       " 'Andrew Yang': 9,\n",
       " 'Michael Bloomberg': 10,\n",
       " 'Pete Buttigieg': 11,\n",
       " 'Bernie Sanders': 12,\n",
       " 'Elizabeth Warren': 13,\n",
       " 'Joe Biden': 14}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all candidates, sorted alphabetically for now. This should eventually be changed to reflect their dropout order (1st to drop --> winner)\n",
    "#candidates  = ['Amy Klobuchar','Andrew Yang','Bernie Sanders','Cory Booker','Deval Patrick','Elizabeth Warren','Joe Biden','John Delaney','Marianne Williamson','Michael Bennet','Michael Bloomberg','Pete Buttigieg','Tom Steyer','Tulsi Gabbard']\n",
    "candidates = list(candidateScoresSorted.keys())\n",
    "\n",
    "candidateDictionary = {} # we need to assign each candidate a numerical value. This will be alphabetical\n",
    "\n",
    "for candidate in range(0,len(candidates)):\n",
    "    candidateDictionary[candidates[candidate]] = candidate + 1\n",
    "    \n",
    "# add a score column to df\n",
    "data['score'] = 0\n",
    "\n",
    "candidateDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoringFunction(rowIndex):\n",
    "    participantN = []\n",
    "    candidatesN = []\n",
    "\n",
    "    # need to convert each survey respondent's string answers into numbers, using the dictionary\n",
    "    for column in data.columns[:-6]:\n",
    "        participantN.append(candidateDictionary[data[column][rowIndex]])\n",
    "\n",
    "    # convert the candidates list into numbers too, using the same dictionary. This is what we compare against.\n",
    "    #for num in range(0,len(candidates)):\n",
    "    #    candidatesN.append(candidateDictionary[candidates[num]])\n",
    "\n",
    "    candidatesN = [4, 5, 3, 9, 1, 2, 6, 11, 8, 10, 13, 7, 12, 14]\n",
    "    \n",
    "    return kendall_tau_distance(candidatesN, participantN)\n",
    "\n",
    "# Use only for final scoring after all but one candidate has dropped out\n",
    "for num in range(0,len(data)):\n",
    "    data['score'][num] = scoringFunction(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to keep score *as* candidates drop out? When there are still unknowns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partialScoringFunction(rowIndex, candidatesDroppedSoFar):\n",
    "    \"\"\"\n",
    "    candidatesDroppedSoFar is a list of all candidates who have dropped out. Ex: [\"Kamala Harris\", \"Beto O'Rourke\"]\n",
    "    \"\"\"\n",
    "       \n",
    "    # convert candidatesDroppedSoFar list into numbers using the dictionary\n",
    "    candidatesDroppedSoFarN = []\n",
    "    for candidate in candidatesDroppedSoFar:\n",
    "        candidatesDroppedSoFarN.append(candidateDictionary[candidate])\n",
    "    \n",
    "    # convert each survey respondent's string answers into numbers, using the dictionary\n",
    "    participantN = []\n",
    "    for column in data.columns[:-6]:\n",
    "        participantN.append(candidateDictionary[data[column][rowIndex]])\n",
    "    \n",
    "    # create new participant list. Candidates who have dropped out so far keep their spot, but \n",
    "    # all other guess positions are replaced with 1-14 (minus the candidates who dropped already)\n",
    "    num = 1\n",
    "    newParticipantList = []\n",
    "    for item in participantN:\n",
    "        if item in candidatesDroppedSoFarN:\n",
    "            newParticipantList.append(item) # candidates who have dropped out retain their drop out predicted spot\n",
    "        else:\n",
    "            while num in candidatesDroppedSoFarN:\n",
    "                num = num + 1\n",
    "            newParticipantList.append(num) # candidates who are still going get replaced with 1-14 (minus drop outs)\n",
    "            num = num + 1\n",
    "\n",
    "    return kendall_tau_distance(candidatesN, newParticipantList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Marianne Williamson is the first to drop, followed by Cory Booker, John Delaney, Andrew Yang, Michael Bennet, Deval Patrick, etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candidateDictionary['Marianne Williamson'])  # Delaney = 4\n",
    "print(candidateDictionary['Cory Booker'])  # Booker = 5\n",
    "print(candidateDictionary['John Delaney'])  # Delaney = 3\n",
    "print(candidateDictionary['Andrew Yang'])  # Yang = 9\n",
    "print(candidateDictionary['Michael Bennet'])  # Bennet = 1\n",
    "print(candidateDictionary['Deval Patrick'])  # Patrick = 2\n",
    "print(candidateDictionary['Tom Steyer'])  # Steyer = 6\n",
    "print(candidateDictionary['Pete Buttigieg'])  # pete = 11\n",
    "print(candidateDictionary['Amy Klobuchar'])  # amy = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we update the candidates list accordingly, moving \"4\" and \"5\" (in that order) to the front of the chopping order list\n",
    "candidatesN = [4, 5, 3, 9, 1, 2, 6, 11, 8, 10, 13, 7, 12, 14]\n",
    "\n",
    "for num in range(0,len(data)):\n",
    "    data['score'][num] = partialScoringFunction(num, [\"Marianne Williamson\", \"Cory Booker\", \"John Delaney\", \"Andrew Yang\", 'Michael Bennet', 'Deval Patrick', 'Tom Steyer', 'Pete Buttigieg', 'Amy Klobuchar', \"Michael Bloomberg\", \"Elizabeth Warren\", \"Tulsi Gabbard\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores Normalized And Converted Into Accuracy Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(tauScore):\n",
    "\n",
    "    # normalized tau score = tau_distance / (n * 15-1 / 2)\n",
    "    # accuracy percentage = 100 - normalized score (which is 0-1)\n",
    "\n",
    "    return 100 - tauScore / (14 * (14-1) / 2) * 100\n",
    "\n",
    "#output_data = data.filter(['participant','twitter', 'privacyPreference', 'alias', 'score']) # remove candidate-prediction columns\n",
    "output_data = data\n",
    "\n",
    "output_data['percentage'] = output_data['score'].apply(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data For Leaderboard And Export To CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripAt(value):\n",
    "    return value.strip(\"@\")\n",
    "\n",
    "def firstNameLastInitial(name):\n",
    "    firstName = name.split(\" \")[0]\n",
    "    lastName = name.split(\" \")[1]\n",
    "    \n",
    "    return firstName + \" \" + lastName[0] + \".\"\n",
    "\n",
    "# for people who submitted twice, delete their first submission\n",
    "output_data = output_data.drop_duplicates('participant',keep=\"last\").reset_index()\n",
    "del output_data['index']\n",
    "\n",
    "output_data['twitter'] = output_data['twitter'].fillna(\"\")\n",
    "output_data['twitter'] = output_data['twitter'].apply(stripAt)\n",
    "\n",
    "# Some participants gave me their twitter handles but don't want the handles posted on the leaderboard\n",
    "# Loop removes their twitter handle before exporting data\n",
    "for num in range(0,len(output_data)):\n",
    "    if output_data['privacyPreference'][num] == 'Yes, and please include my Twitter handle as well':\n",
    "        continue\n",
    "    else:\n",
    "        output_data['twitter'][num] = \"\"\n",
    "        \n",
    "# Remove last names from participant names (leave the initial) \n",
    "# Or replace with their self-chosen alias if that's their preference\n",
    "output_data['name'] = ''\n",
    "\n",
    "for num in range(0,len(output_data)):\n",
    "    if output_data['privacyPreference'][num] == 'Yes':\n",
    "        output_data['name'][num] = firstNameLastInitial(output_data['participant'][num])\n",
    "    elif output_data['privacyPreference'][num] == 'Yes, and please include my Twitter handle as well':\n",
    "        output_data['name'][num] = firstNameLastInitial(output_data['participant'][num])\n",
    "    elif output_data['privacyPreference'][num] == 'No, list me as \"Anonymous\"':\n",
    "        output_data['name'][num] = 'Anonymous'\n",
    "    elif output_data['privacyPreference'][num] == 'fullName':\n",
    "        output_data['name'][num] = output_data['participant'][num]\n",
    "    else:\n",
    "        output_data['name'][num] = output_data['alias'][num]\n",
    "        \n",
    "output_data = output_data.sort_values(['percentage', 'name'], ascending=[False, True])\n",
    "output_data = output_data.reset_index()\n",
    "del output_data['index']\n",
    "\n",
    "output_data.to_csv(\"scoreboardDataApril8.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis For Random Tidbits Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this reformatted data will be necessary for answering certain questions\n",
    "reformattedData = {'participant':[]}\n",
    "\n",
    "for row in range(0,len(data)):\n",
    "    for column in data.columns[:-6]:\n",
    "        if column == 'participant':\n",
    "            reformattedData['participant'].append(data[column][row])\n",
    "        elif data[column][row] not in reformattedData:\n",
    "            reformattedData[data[column][row]] = [int(column)]\n",
    "        elif data[column][row] in reformattedData:\n",
    "            reformattedData[data[column][row]].append(int(column))\n",
    "            \n",
    "reformattedData = pd.DataFrame(reformattedData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 42% of participants predict Biden will be the eventual nominee. Warren and Bernie are the next most common guesses (tied with 25% each)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[14].value_counts() / len(data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Michael Bennet is by far the most popular guess for first-to-drop (31% of submissions). John Delaney is next, with 17% predicting he'll be out first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1].value_counts() / len(data) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73% of participants predict Bennet will be among the first 3 candidates to drop out. Delaney (49%), Deval Patrick (45%), and Cory Booker (38%) are all also common 'first 3' picks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"% of respondents who think candidate will be one of the next four to drop out\")\n",
    "print(\" \")\n",
    "\n",
    "for candidate in candidates:\n",
    "    print(candidate + \": \" + str(len(reformattedData[reformattedData[candidate] <= 3]) / len(data) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contest participants disagree the most over Cory Booker's chances - it's common to see him all over the place in guesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for candidate in candidates:\n",
    "    print(candidate + \" : \" + str(statistics.stdev(reformattedData[candidate])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Want/need/predicted ____ out next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidatesIn = [\"Tulsi Gabbard\", \"Amy Klobuchar\", \"Michael Bloomberg\", \"Pete Buttigieg\", \"Bernie Sanders\", \"Elizabeth Warren\"]\n",
    "\n",
    "need__OutNext = 0\n",
    "candidate = ''\n",
    "\n",
    "for row in range(0,len(data)):\n",
    "    for column in data.columns[:-14]:\n",
    "        if data[column][row] in candidatesIn:\n",
    "            break\n",
    "        if data[column][row] == candidate:\n",
    "            need__OutNext = need__OutNext + 1\n",
    "            \n",
    "print(need__OutNext / len(data) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
